{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ff0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import DBSCAN\n",
    "from itertools import product\n",
    "from scipy.stats import multivariate_normal\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_dim_noise(grid_dims, amount, step, std=10, means=(1,5)):\n",
    "    prod = reduce((lambda x,y: x*y), grid_dims)\n",
    "    samples = np.zeros(grid_dims + [amount , len(grid_dims)])\n",
    "    clusters = np.random.randint(\n",
    "        means[0], means[1] + 1, size=grid_dims\n",
    "    )\n",
    "    \n",
    "    grid = []\n",
    "    for dim in grid_dims:\n",
    "        grid.append(((np.arange(dim) + 1) * step))\n",
    "\n",
    "    mean = np.array(np.meshgrid(*grid, indexing=\"ij\")).reshape(prod, len(grid_dims))\n",
    "    noise = np.random.randn(means[1], prod, len(grid_dims)) * std\n",
    "    centers = (noise + mean).reshape([means[1]] + grid_dims + [len(grid_dims)])\n",
    "    \n",
    "    # transpose hack for selection\n",
    "    roll_idx = np.roll(np.arange(centers.ndim),-1).tolist()\n",
    "    centers = np.transpose(centers, roll_idx)\n",
    "\n",
    "    for idxs in product(*[range(i) for i in grid_dims]):\n",
    "        print(idxs)\n",
    "        samples[idxs] = make_blobs(\n",
    "            n_samples=amount, centers=(centers[idxs][:, 0:clusters[idxs]]).T\n",
    "        )[0]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(width, length, amount, step, std=10, means=(1,5)):\n",
    "        samples = np.zeros((width, length, amount, 2))\n",
    "\n",
    "        clusters = np.random.randint(\n",
    "            means[0], means[1] + 1, size=(width, length)\n",
    "        )\n",
    "\n",
    "        # calculate centers\n",
    "        grid_width = (np.arange(width) + 1) * step\n",
    "        grid_length = (np.arange(length) + 1) * step\n",
    "        mean = np.array(\n",
    "            [\n",
    "                np.repeat(grid_width, len(grid_length)),\n",
    "                np.tile(grid_length, len(grid_width)),\n",
    "            ]\n",
    "        ).T\n",
    "        noise = np.random.randn(means[1], width * length, 2) * std\n",
    "        centers = (noise + mean).reshape((means[1], width, length, 2))\n",
    "\n",
    "        for i in range(width):\n",
    "            for j in range(length):\n",
    "                samples[i, j, :] = make_blobs(\n",
    "                    n_samples=amount, centers=centers[0 : clusters[i, j], i, j, :]\n",
    "                )[0]\n",
    "\n",
    "        return samples, (grid_width, grid_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data, map_grid = generate_noise(3, 3, 50, 10)\n",
    "multi_dim_noise([4,2,5], 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62457053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[0,0,:,0], data[0,0,:,1], 'o') # example of 5 clusters in position 0,0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c464af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_map(noise, eps=2, min_samples=3):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(noise)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    return labels, core_samples_mask, n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, labels, core_sapmles_mask, n_clusters_):\n",
    "    \n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each)\n",
    "              for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "\n",
    "        xy = X[class_member_mask & core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=14)\n",
    "\n",
    "        xy = X[class_member_mask & ~core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=6)\n",
    "    plt.title('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637287d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((3, 3, 50), dtype=int)\n",
    "for x,y in product(range(3), range(3)):\n",
    "    labels[x,y,:], core_samples_mask, n_clusters_ = generate_map(data[x,y,:,:])\n",
    "    plot_clusters(data[x,y,:,:], labels[x,y,:], core_samples_mask, n_clusters_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate parameters\n",
    "# this is quite slow but calculation is perfomed only once per map generation\n",
    "\n",
    "params = [[[] for i in range(3)] for i in range(3)]\n",
    "\n",
    "for x,y in product(range(3), range(3)):\n",
    "    used_data = 50 - list(labels[x,y]).count(-1)\n",
    "    \n",
    "    for i in range(np.max(labels[x,y,:]) + 1):\n",
    "        mask = labels[x,y] == i\n",
    "        mean_noise = data[x,y,mask,:].mean(axis=0) - np.array([(x+1) * 10,(y+1) * 10])\n",
    "        cov_noise = np.cov(data[x,y,mask,:].T)\n",
    "        weight = mask.sum() / used_data\n",
    "        params[x][y].append((mean_noise, cov_noise, weight))\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3538813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamics model\n",
    "\n",
    "walk = []\n",
    "start_state = np.array([[20, 20, 0, 0]], dtype=float)\n",
    "walk.append(start_state)\n",
    "\n",
    "def transition_function(current_state, x_range=(10, 40), y_range=(10, 40), std=1):\n",
    "    \"\"\"Performs a one step transition assuming sensing interval of one\n",
    "    \n",
    "    Format of current_state = [x,y,x',y'] + first dimension is batch size\n",
    "    \"\"\"\n",
    "    next_state = np.copy(current_state)\n",
    "    next_state[: ,0:2] += current_state[:, 2:4]\n",
    "    next_state[: ,2:4] += np.random.randn(2) * std\n",
    "    \n",
    "    \n",
    "    next_state[: ,0] = np.clip(next_state[: ,0], x_range[0], x_range[1])\n",
    "    next_state[: ,1] = np.clip(next_state[: ,1], y_range[0], y_range[1])\n",
    "    return next_state\n",
    "\n",
    "next_state = transition_function(start_state)\n",
    "walk.append(next_state)\n",
    "for i in range(100):\n",
    "    next_state = transition_function(next_state)\n",
    "    walk.append(next_state)\n",
    "walk = np.array(walk)\n",
    "print(walk.shape)\n",
    "plt.plot(walk[:,0,0], walk[:,0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement noise map augmented particle filter\n",
    "\n",
    "def find_nearest_map_position(x,y, map_grid):\n",
    "    x_pos = np.searchsorted(map_grid[0], x)\n",
    "    y_pos = np.searchsorted(map_grid[1], y, side=\"right\")\n",
    "\n",
    "    x_valid = (x_pos != 0) & (x_pos < len(map_grid[0]))\n",
    "    x_pos = np.clip(x_pos, 0, len(map_grid[0]) - 1)\n",
    "    x_dist_right = map_grid[0][x_pos] - x\n",
    "    x_dist_left = x - map_grid[0][x_pos - 1]\n",
    "    x_pos[x_valid & (x_dist_right > x_dist_left)] -= 1\n",
    "    \n",
    "    y_valid = (y_pos != 0) & (y_pos < len(map_grid[1]))\n",
    "    y_pos = np.clip(y_pos, 0, len(map_grid[1]) - 1)\n",
    "    y_dist_right = map_grid[1][y_pos] - y\n",
    "    y_dist_left = y - map_grid[0][y_pos - 1]\n",
    "    y_pos[y_valid & (y_dist_right > y_dist_left)] -= 1  \n",
    "  \n",
    "    return x_pos, y_pos\n",
    "\n",
    "\n",
    "def reweight_samples(x, z, w, params, map_grip):\n",
    "    x_pos, y_pos = find_nearest_map_position(x[:,0], x[:,1], map_grid)\n",
    "    new_weights = np.zeros_like(w)\n",
    "    \n",
    "    for i, (x_p, y_p) in enumerate(zip(x_pos, y_pos)):\n",
    "        for gm in params[x_p][y_p]:\n",
    "            # calculating p(z|x) for GM\n",
    "            mean, cov, weight = gm\n",
    "            new_weights[i] += multivariate_normal.pdf(z[i, 0:2] ,mean=mean, cov=cov) * weight * w[i]\n",
    "    denorm = np.sum(new_weights)\n",
    "    return new_weights / denorm\n",
    "                \n",
    "    \n",
    "print(map_grid)\n",
    "x = np.array([9, 10, 11, 14, 16, 24, 31, 30, 29, 15])\n",
    "y = np.array([9, 10, 11, 14, 16, 24, 31, 30, 29, 15])\n",
    "w = np.ones(10) * 0.1\n",
    "print(find_nearest_map_position(\n",
    "    x,\n",
    "    y,\n",
    "    map_grid\n",
    "))\n",
    "x_noise = np.random.randn(10)\n",
    "y_noise = np.random.randn(10)\n",
    "particles = np.stack((x, y, x_noise, y_noise)).T\n",
    "transitioned_particles = transition_function(particles)\n",
    "\n",
    "n_w = reweight_samples(particles, transitioned_particles, w, params, map_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f298db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics for resampling\n",
    "\n",
    "def compute_ESS(x, w):\n",
    "    M = len(x)\n",
    "    CV = 1/M * np.sum((w*M-1)**2)\n",
    "    return M / (1 + CV)\n",
    "\n",
    "print(compute_ESS(particles, w))\n",
    "print(compute_ESS(particles, n_w)) # needs to be resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34660859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
